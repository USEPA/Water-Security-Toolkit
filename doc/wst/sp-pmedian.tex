
The \code{sp} subcommmand can design a sensor network for contamination
warning systems (CWSs) using a variety of different optimization
formulations. The most widely studied sensor placement formulation
for CWS design is to minimize the expected impact of an ensemble
of contamination incidents given a sensor budget. This formulation
has also become the standard formulation for \code{sp}, because it
can be effectively used to select sensor placements in large water
distribution networks. This chapter provides a variety of examples
that illustrate the application of the \code{sp} subcommand for this optimization formulation.
Sensor placement formulation and examples illustrating common use of \code{sp} are included in Chapter~\ref{chap:sp}.

\subsection{Computing a Bound on the Best Sensor Placement Value}\label{solvers_solvers2a}

A mixed-integer program (MIP) solver like GLPK provide upper and lower bounds on the value
of the final solution. For large water distribution systems, it
might be prohibitively expensive to perform optimization with a MIP
solver. However, computing a lower bound with these solvers might
be practical even for large water distribution systems.

The configuration file shown in Figure \ref{fig:sp_bound}
defines a sensor placement problem with the compute bound option set to true in the 
problem block. This option indicates that the goal for the optimizer is to compute a lower bound 
on the globally optimal solution, rather than finding a sensor placement. 
All other options are those previously defined in example 3 of the Sensor 
Placement Examples (See Section~\ref{sp_example}).

\begin{figure}[h]
  \unknownInputListing{examples/sp/sp_bound.yml}{}{1}{28}
  \caption{The \code{sp} configuration file using the GLPK solver to compute a lower bound.}
  \label{fig:sp_bound}
\end{figure}

The YAML output file in Figure \ref{fig:sp_bound_output} contains the lower bound value. 
This is the same value as the solution generated by the GRASP heuristic in 
example 3 of the Sensor Placement Examples (See Section~\ref{sp_example}). 
In this manner, a MIP solver can be used to evaluate whether a heuristic 
sensor placement is near-optimal.

\begin{figure}[h]
  \unknownInputListing{examples/sp/sp_bound_output.yml}{}{1}{14}
  \caption{The \code{sp} YAML file with the lower bound from the GLPK solver.}
  \label{fig:sp_bound_output}
\end{figure}

The Lagrangian heuristic leverages the structure of the eSP model (Equations~\ref{eqn:eSP}) to
guide its search. Specifically, this heuristic computes the optimal values for the 
integer relaxation of eSP and then applies a randomized rounding technique.
As a consequence, this heuristic can also be used to compute bounds on the value of 
sensor placement in a manner that is similar to a MIP solver.
The configuration file in Figure 
\ref{fig:sp_bound_lag} uses the Lagrangian solver to determine the sensor placement 
for example 3 of the Sensor Placement Examples (See Section~\ref{sp_example}). 

\begin{figure}[h]
  \unknownInputListing{examples/sp/sp_bound_lag.yml}{}{1}{28}
  \caption{The \code{sp} configuration file using the Lagrangian solver.}
  \label{fig:sp_bound_lag}
\end{figure}

The YAML output file in Figure \ref{fig:sp_bound_lag_yaml} shows
the results of sensor placement using the Lagrangian solver for
example 3 of the Sensor Placement Examples (See Section~\ref{sp_example}).
It contains the sensor locations (EPANET IDs), the objective value
(the impact metric value), the lower bound on this objective as
well as the upper bound, which is the same as the objective value.
The sensor locations identified are nodes 139,
161, 191 and 208. The mean extent of contamination (EC) impact for
this design is approximately 9889 pipe feet contaminated. The lower
bound is approximately 9819 pipe feet contaminated, which is greater than the
bound computed by GLPK. This illustrates the fact that the bounds computed
by the Lagrangian solver are weaker than those computed by a MIP solver.

\begin{figure}[h]
  \unknownInputListing{examples/sp/sp_bound_lag_output.yml}{}{1}{14}
  \caption{The \code{sp} YAML file with the lower bound from the Lagrangian solver.}
  \label{fig:sp_bound_lag_yaml}
\end{figure}

As with MIP solvers, the Lagrangian solver can also be used to simply compute this lower bound.  
The configuration file in Figure \ref{fig:sp_bound_only_lag} shows an example of using the 
compute bound option in the problem block with the Lagrangian solver.

\begin{figure}[h]
  \unknownInputListing{examples/sp/sp_bound_only_lag.yml}{}{1}{29}
  \caption{The \code{sp} configuration file using the Lagrangian solver and the compute bound option.}
  \label{fig:sp_bound_only_lag}
\end{figure}

\subsection{Managing Sensor Placement Locations}\label{solvers_solvers2c}

By default, the \code{sp} subcommand assumes that all node locations in
a water distribution network are feasible sensor locations. 
In practice, sensors cannot be practically installed in many locations without
significant cost and inconvenience. The location block in the 
configuration file is used to specify options for declaring feasible and infeasible
node locations in the network. Additionally, the location block
can be used to declare node locations as fixed, where a sensor must be
placed, and unfixed, where a sensor cannot be located.

A location block consists of a list of declarations that are
interpreted in their order within the configuration file. Each
declaration consists of a dictionary with a single key, whose value
is either a string or list of EPANET node IDs. For example, the following location
block declares a list of infeasible node locations:
\unknownInputListing{examples/sp/fixed1.yml}{block}{22}{28}

The impact of infeasible sensor locations on the results
for example 1 of the Sensor Placement Examples (See
Section~\ref{sp_example}) is shown in following example. The solution from this example placed
sensors at nodes 113, 121, 141, 163 and 209 and the mean extent of
contamination (EC) for this sensor design was 8655. If these nodes
were listed as infeasible sensor locations (as shown in the location
block above) in the configuration file, the new sensor locations
are nodes 111, 119, 169, 207 and 237. The mean EC for this new
solution is 8932 which is worse than the initial design; this
reflects the fact that a sensor design that can use any location
will be better than a sensor design that can use a limited set of
locations.


\subsection{Limited-\/Memory Sensor Placement Techniques}\label{solvers_solvers5}

Controlling the memory used by optimizers is a critical issue when
solving large sensor placement formulations. This is a particular
challenge for MIP methods, but both the GRASP and Lagrangian
heuristics can exceed a workstation's memory when solving very large
problems. The \code{sp} subcommand supports a variety of mechanisms
that reduce the problem representation size while preserving the
structure of the sensor placement problem. These techniques include:
scenario aggregation and filtering, feasible locations, witness
aggregation, skeletonization and explicit memory management.

\paragraph{Scenario Aggregation:}
Scenario aggregation compresses the data in an impact file while
preserving its fundamental structure. This strategy is effective
when optimizing for mean performance objectives. Scenario aggregation
is performed with the \code{scenarioAggr} command, which is described
in Section~\ref{scenarioAggrExecutable}.

\paragraph{Filtering Impacts:}
Filtering impacts can also reduce memory requirements for sensor
placement by reducing the size of the impact files. Filtering can
limit the sensor placement formulation to only consider contamination
incidents that are sufficiently bad in the worst-\/case. Filtering
is performed with the \code{filter\_\-impacts} executable, which
is described in Section~\ref{filter_impactsExecutable}

\paragraph{Feasible Locations:}
Limiting the feasible locations is another strategy to reduce memory
requirements. The size of the sensor placement formulation
decreases as the number of feasible locations decreases. The
location block option described in Section~\ref{solvers_solvers2c}
can be used to specify the set of feasible locations.

\paragraph{Witness Aggregation:}
Witness aggregation limits the size of the sensor placement formulation
by aggregating the decision variables that witness a contamination
incident. By default, variables that witness contamination incidents
with the same impact are aggregated, and this typically reduces the
MIP constraint matrix by a significant amount. Further reductions
perform more aggressive aggregations that create an approximate
sensor placement formulation.

Witness aggregation is specified using an \code{aggregate} block
in the \code{sp} configuration file. A named aggregation block
specifies the type of aggregation, the aggregation limit value and
the associated impact data. For example:\newline
\begin{minipage}{\textwidth}
\begin{unknownListing}
aggregate: 
- name: agg1
  type: PERCENT
  goal: impact1
  value: 0.125
  conserve memory: 0
  distinguish detection: 0
  disable aggregation: [0]
\end{unknownListing}
\end{minipage}

The following table illustrates the use of the two witness aggregation
options when optimizing the mean extent of contamination: aggregation
type = PERCENT and aggregation type = RATIO. The RATIO aggregation
type can be used with distinguish detection option to help with
aggregation. The second line of data in this table is the default
aggregation, which has about half as many non-\/zero values in the
MIP constraint matrix. Both the percent and ratio aggregation
strategies effectively reduce the problem size while finding
near-\/optimal solutions.

\begin{center}
\begin{tabularx}{\textwidth}{|l|l|c|r|r|} \cline{1-5}
Aggregation Type & Aggregation Value & Binary Variables & MIP Nonzeros&Solution Value  \\\cline{1-5}
None&NA&97&220736&8525  \\\cline{1-5}
PERCENT&0.0&97&119607&8525  \\\cline{1-5}
PERCENT&0.125&97&49576&9513  \\\cline{1-5}
RATIO&0.125&97&12437&10991  \\\cline{1-5}
\end{tabularx}
\end{center} 

\paragraph{Skeletonization:} 
Another option to reduce the memory
requirement for sensor placement is to reduce the size of the network
model through skeletonization. Skeletonization groups neighboring
nodes based on the topology of the network and pipe attributes.
Section~\ref{skelExecutable} describes the \code{spotSkeleton}
executable, which provides techniques for branch trimming, series
pipe merging and parallel pipe merging. These techniques eliminate
pipes and nodes that have little effect on the overall hydraulics
of the system. This effectively contracts a connected piece of the
network into a single node, called a supernode. Skeletonized
networks can be used to define geographic proximity in a two-tiered
sensor placement approach for large network models~\citep{KliPhiJan13}.

\paragraph{Explicit Memory Management:}
The GRASP heuristic has several options for controlling how memory 
is managed. The \code{grasp-\/representation} solver option can be used to 
control how the local search steps are performed. By default, a dense matrix is 
precomputed to perform local search steps quickly, but a sparse matrix can be 
used to perform local search with less memory. Also, the GRASP heuristic can be 
configured to use the local disk to store this matrix.


\subsection{Evaluating a Sensor Placement}\label{solvers_solvers6}

Sensor placements can be evaluated based on an impact assessment of possible contaminant incidents.  
The \code{evalsensor} executable measures the performance of each sensor placement
with respect to the set of possible contamination locations. This analysis
assumes that probabilities have been assigned to these contamination
locations. If no probabilities are given, then uniform probabilities
are used. The \code{evalsensor} executable takes sensor placements in a sensor placement 
file and evaluates them using data from one or more impact files.
Sensor placement files are generated using the \code{sp} subcommand, and the file format is described 
in File Formats Section \ref{formats_sensorPlacementFile}. Impact files 
are generated using the \code{sim2Impact} subcommand, and the file format is described 
in the File Formats Section \ref{formats_impactFile}. Additional information on 
\code{evalsensor} can be found in the Executable Files Section \ref{evalsensorExecutable}.

The following example demonstrates the use of \code{evalsensor} using the sensor 
network design from Section~\ref{sp_example}.
The \code{evalsensor} command for this example is executed using the following command:

\begin{unknownListing}
evalsensor --nodemap=Net3.nodemap Net3_ec.sensors Net3_ec.impact Net3_mc.impact
\end{unknownListing}

This example generates output shown in Figure \ref{fig:evalsensor_ex1_screen_output}.

\begin{figure}[h]
  \unknownInputListing{examples/sp/evalsensor_ex1_screen_output.txt}{}{1}{29}
  \caption{The \code{evalsensor} example output.}
  \label{fig:evalsensor_ex1_screen_output}
\end{figure}

The \code{evalsensors} command can also evaluate a sensor placement in the 
case where sensors can fail, and there is some small number of different classes 
of sensors (grouped by false negative probability). This information is specified 
by an imperfect sensor class file and an imperfect junction class file, which are defined in 
Sections~\ref{formats_sensorClass} and~\ref{formats_junctionClass}, 
respectively. The imperfect sensor class (sc) file, \code{Net3.imperfectsc}, specifies different 
categories of sensor failures. Sensors of class 1 have a 
false negative probability of 25\%, sensors of class 2 have a probability of 50\%, 
class 3 have a 75\% probability and class 4 100\%. 

\lstinputlisting[]{../../examples/Net3/Net3.imperfectsc}

Once failure classes are defined, the nodes of the network are assigned 
to failure classes by using a imperfect junction class (jc) file. The beginning of the 
imperfect junction class file Net3.imperfectjc is shown below.

\lstinputlisting[firstline=0,lastline=10]{../../examples/Net3/Net3.imperfectjc}

Given the junction classes, \code{evalsensor} is used to determine the 
expected impact of a sensor placement, given that sensors might fail. 
The following command line executes \code{evalsensor} with specified failure probabilities:

\begin{unknownListing}
evalsensor --nodemap=Net3.nodemap --sc-probabilities=Net3.imperfectsc \
    --scs=Net3.imperfectjc Net3_ec.sensors Net3_ec.impact
\end{unknownListing}

This example generates output shown in Figure \ref{fig:evalsensor_ex2_screen_output}.

\begin{figure}[h]
  \unknownInputListing{examples/sp/evalsensor_ex2_screen_output.txt}{}{1}{18}
  \caption{The \code{evalsensor} output using sensor failure probabilities.}
  \label{fig:evalsensor_ex2_screen_output}
\end{figure}

The mean extent of contamination impact changes dramatically 
if sensors are allowed to fail. The original solution was 
misleading if sensors fail according to the assigned probabilities. 
With sensor failures, the expected impact is much higher.
